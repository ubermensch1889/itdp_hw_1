# Инструкция по развертыванию кластера hdfs

### Дано
- 4 виртуальных машины: jump-node, name-node и 2 датаноды

### Первоначальная настройка доступов между нодами

Итак, подключемся к jump-node, используя команду:\
`ssh team@<адрес вашей вм>`

Сделаем так, чтобы наши узлы были доступны по именам. Для этого необходимо открыть файл /etc/hosts, используя, например, такую команду:\
`sudo nano /etc/hosts`

Далее заменяем содержимое файла на следующий текст:
```
# 192.168.1.30    tmpl-jn
192.168.1.31    tmpl-nn
192.168.1.32    tmpl-dn-00
192.168.1.33    tmpl-dn-01
```
Обратите внимание на первую строку. Она закомментирована. После этого нужно пройтись по всем узлам и так же заменить содержимое аналогичного файла на данный текст, 
но вместо первой строки, нужно закомментировать строку, соответствующую узлу, на котором вы находитесь. Для того, чтобы подключиться к другому узлу, выполним команду\
`ssh tmpl-<nn/dn-00/dn-01`\
Для отключения существует команда `exit`.

Чтобы проверить, что все сделано правильно, можно воспользоваться командой  
`ping tmpl-<nn/dn-00/dn-01>`

После этого нам необходимо на всех узлах создать пользователя, от имени которого будут выполняться сервисы hadoop. Для этого на каждой ноде выполним команду\
`sudo adduser hadoop`\
Пароль придумываем на свое усмотрение. Чтобы сменить пользователя, вводим команду `sudo -i -u <имя пользователя`.

### Развертывание hdfs

Чтобы скачать дистрибутив hadoop, вернемся на jump-node и выполним команду  
`wget https://dlcdn.apache.org/hadoop/common/hadoop-3.4.0/hadoop-3.4.0.tar.gz`

Дождемся загрузки. После этого переместим скаченный файл на другие узлы. Пишем в консоль (отдельно каждого из 3 узлов):  
`scp hadoop-3.4.0.tar.gz tmpl-<nn/dn-00/dn-01>:/home/hadoop`

Распакуем на каждой ноде.  
`tar -xzvf hadoop-3.4.0.tar.gz`

Теперь необходимо узнать версию java - `java -version`. Насколько мне известно, Hadoop способен работать с версиями 5 и выше (но это неточно). Если у нас нет java или не подходящая версия, то устанавливаем нужную версию java.

Далее найдем местоположения java. Вводим `which java`. Полученный результат копируем. Вводим `readlink -f <результат выполнения прошлой команды`. Копируем этот путь.

Добавляем нужные переменные окружения. Для этого отрываем файл .profile (`nano ~/.profile`). Пишем в конце:
```
export HADOOP_HOME=/home/hadoop/hadoop-3.4.0
export JAVA_HOME=<путь до жабы>
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```
Активируем изменения с помощью команды `source ~/.profile`.

Теперь можем проверить работу Hadoop. Введем `hadoop version`. Повторяем аналогичные действия на остальных нодах (можно перенести файл .profile с помощью команды scp).

Возвращаемся на jump-node, чтобы настроить конфиги. Переходим в директорию ~/hadoop-3.4.0/etc/hadoop/. Открываем файл hadoop-env.sh (аналогично с тем, как мы делали это раньше) и добавляем туда строчку  
`JAVA_HOME=<путь к жабе>`

Правим файл core-site.xml в той же папке. Пишем туда
```
<configuration>
<property>
        <name>fs.defaultFS</name>
        <value>hdfs://tmpl-nn:9000</value>
</property>
</configuration>
```

В файл hdfs-site.xml:
```
<configuration>
<property>
        <name>dfs.replication</name>
        <value>3</value>
</property>
</configuration>
```

Также редактируем файл workers. Заменяем содержимое на следующие строчки:
```
tmpl-nn
tmpl-dn-00
tmpl-dn-01
```

Производим аналогичные махинации на других нодах (или копируем туда файлы с помощью команды scp).

Теперь переходим на namenode. Перемещаемся в каталог hadoop-3.4.0/. В нем запускаем команду, которая создаст файловую систему.  
`bin/hdfs namenode -format`

Запускаем кластер.  
`sbin/start-dfs.sh`

Чтобы проверить, что класер запущен, выполним команду jps. Если она вывела DataNode, NameNode и SecondaryNameNode, то кластер работает. Можно перейти на datanod'ы и посмотреть, работает ли кластер там. На датанодах эта команда должна вывести DataNode. 

Также можем посмотреть логи. Для этого просмотрим содержимое файлов в директории ~/hadoop-3.4.0/logs. Если там нет ошибок ни на одном из узлов, то, скорее всего, все хорошо.

__Автор__: Сангаджиев Эренцен
